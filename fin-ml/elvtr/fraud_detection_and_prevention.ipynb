{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813d3678",
   "metadata": {},
   "source": [
    "#  Coding Assignment #3 - Fraud Detection Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578b98d",
   "metadata": {},
   "source": [
    "# Introduction to Fraud Detection Assignment\n",
    "\n",
    "In this assignment, you will embark on an analytical journey to explore and model a dataset of card transactions with the aim of detecting fraudulent activities. The provided dataset includes various features such as distance from home, transaction details, and purchase patterns, which are essential in understanding the characteristics of fraudulent transactions. You will use Python and key machine learning libraries to analyze this dataset, build a classification model, and evaluate its performance.\n",
    "\n",
    "## Base Code Provided\n",
    "- The base code includes necessary Python imports and a decision tree model for initial analysis.\n",
    "- You will start with a dataset of card transactions, exploring its structure, summary statistics, and event rate.\n",
    "- The base code will guide you through data loading, preprocessing, model training, and evaluation.\n",
    "- A visual representation of the decision tree will be created to help understand the model's decision-making process.\n",
    "\n",
    "## Your Tasks\n",
    "- **Data Analysis**: Deepen your understanding of the dataset by performing additional exploratory data analysis.\n",
    "- **Model Building and Evaluation**: Beyond the decision tree, experiment with another model such as Random Forest to compare performance.\n",
    "- **Performance Metrics**: Evaluate models using metrics like precision, recall, and F1-score, and understand the implications of these metrics in the context of fraud detection.\n",
    "- **Advanced Techniques** (Extra Credit): Implement data balancing, feature importance analysis, and cross-validation to enhance model performance and robustness.\n",
    "\n",
    "## Learning Outcomes\n",
    "- Gain practical experience in handling real-world datasets.\n",
    "- Develop skills in building and evaluating classification models.\n",
    "- Learn to interpret model results and make data-driven decisions.\n",
    "- Explore advanced machine learning techniques (optional extra credit).\n",
    "\n",
    "## Submission Guidelines\n",
    "- Submit your enhanced code with clear documentation and comments.\n",
    "- Include a report or inline comments analyzing your findings and model performances.\n",
    "- Ensure your code is clean, well-organized, and reproducible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a84b9",
   "metadata": {},
   "source": [
    "## Fraud Detection Model Workflow Summary\n",
    "\n",
    "1. **Import Libraries**\n",
    "   - `pandas` for data handling.\n",
    "   - `numpy` for numerical operations.\n",
    "   - `sklearn` for machine learning tools.\n",
    "   - `matplotlib` for data visualization.\n",
    "\n",
    "2. **Load Dataset**\n",
    "   - Data is loaded from a remote URL using `pandas.read_csv`.\n",
    "\n",
    "3. **Initial Data Exploration**\n",
    "   - Initial examination using `data.head()` and `data.tail()` to understand dataset structure.\n",
    "\n",
    "4. **Data Preparation**\n",
    "   - Features (`X`) and target variable (`y`) are defined.\n",
    "   - `fraud` column is the target, while others are features.\n",
    "\n",
    "5. **Data Splitting**\n",
    "   - Dataset is split into training and test sets.\n",
    "   - `train_test_split` is used, with a test size of 20%.\n",
    "\n",
    "6. **Model Initialization**\n",
    "   - Decision Tree Classifier initialized with a maximum depth of 3.\n",
    "   - Limits complexity and overfitting of the model.\n",
    "\n",
    "7. **Model Training**\n",
    "   - Model is trained using the training set (`X_train`, `y_train`).\n",
    "\n",
    "8. **Prediction and Evaluation**\n",
    "   - Model predictions made on the test set.\n",
    "   - Evaluation using accuracy, confusion matrix, and classification report.\n",
    "\n",
    "9. **Visualization**\n",
    "   - Decision tree visualized using `matplotlib` and `sklearn.tree.plot_tree`.\n",
    "   - Helps in understanding the decision-making process of the model.\n",
    "\n",
    "# Commentary\n",
    "- This code effectively demonstrates the end-to-end process of a machine learning project.\n",
    "- Decision trees are a good choice for fraud detection due to their interpretability.\n",
    "- The model is simple yet provides a decent understanding of the basic approach to fraud detection in financial transactions.\n",
    "- Visualization is a key aspect, especially in complex domains like fraud detection, for understanding the model's decision criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4949558",
   "metadata": {},
   "source": [
    "# Model Performance Analysis and Commentary\n",
    "\n",
    "- **Data Overview**\n",
    "  - First 5 rows show a mix of numerical features like `distance_from_home`, `distance_from_last_transaction`, etc., crucial for predicting fraud.\n",
    "  - Summary statistics indicate a varied distribution of values, with some features having a wide range (e.g., `distance_from_home`).\n",
    "\n",
    "- **Model Accuracy**\n",
    "  - High accuracy of 98% suggests the model is very effective in classifying transactions as fraudulent or non-fraudulent.\n",
    "\n",
    "- **Confusion Matrix Analysis**\n",
    "  - Low number of false positives (2481) and false negatives (1646) compared to true positives and negatives.\n",
    "  - Indicates a good balance in identifying both fraudulent and non-fraudulent transactions accurately.\n",
    "\n",
    "- **Classification Report Insights**\n",
    "  - High precision (0.99) for class 0 (Non-Fraud) and good precision (0.86) for class 1 (Fraud).\n",
    "  - Recall is also high for both classes, especially for class 1 (0.91), which is critical in fraud detection.\n",
    "  - F1-scores are robust, indicating a balanced model considering both precision and recall.\n",
    "\n",
    "- **Overall Evaluation**\n",
    "  - The decision tree model shows excellent performance in identifying fraud.\n",
    "  - The balance between precision and recall, especially for fraud detection (class 1), is commendable.\n",
    "  - High accuracy combined with the detailed metrics suggest a well-tuned model for this dataset.\n",
    "  - The model could be further improved by exploring feature engineering, trying other algorithms, or tuning hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b780f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deed417b",
   "metadata": {},
   "source": [
    "# Coding Assignment:  Comparative Analysis of Fraud Detection Models\n",
    "\n",
    "## Objective\n",
    "Enhance your skills in model evaluation and comparison in a real-world application: fraud detection. Using the provided Decision Tree model and dataset of card transactions, you will build a Random Forest model and compare its performance against the Decision Tree model.\n",
    "\n",
    "## Tasks\n",
    "1. **Model Building**:\n",
    "   - Build a Random Forest model using the provided dataset.\n",
    "2. **Model Evaluation**:\n",
    "   - Calculate and interpret the precision and recall for the Random Forest model.\n",
    "   - Generate and interpret the confusion matrix for the Random Forest model.\n",
    "3. **Comparative Analysis**:\n",
    "   - Compare the performance of the Decision Tree and Random Forest models using precision, recall, and confusion matrices.\n",
    "   - Visualize the comparison using a bar chart.\n",
    "4. **Reflection and Discussion**:\n",
    "   - Discuss your findings, comparing the two models. Reflect on model performance, suitability for fraud detection, and potential issues like overfitting.\n",
    "\n",
    "## Grading Rubric\n",
    "\n",
    "**Total Points: 100**\n",
    "\n",
    "1. **Model Building (30 Points)**:\n",
    "   - Successfully building a Random Forest model: 30 points\n",
    "\n",
    "2. **Model Evaluation (40 Points)**:\n",
    "   - Correct calculation of precision and recall for the Random Forest model: 20 points\n",
    "   - Correct generation and interpretation of the Random Forest confusion matrix: 20 points\n",
    "\n",
    "3. **Comparative Analysis (20 Points)**:\n",
    "   - Accurate comparison of model performance (including the provided Decision Tree model): 10 points\n",
    "   - Clear and correct visualization using a bar chart: 10 points\n",
    "\n",
    "4. **Reflection and Discussion (10 Points)**:\n",
    "   - Cohesive and thoughtful discussion comparing the two models: 10 points\n",
    "\n",
    "## Submission Guidelines\n",
    "- Submit your work in a Jupyter Notebook or as a Python script with comments explaining your steps. You can also include your discussion in the notebook, as comments in your script, or in a separate text file.\n",
    "- Ensure your plots and tables are clearly labeled and legible.\n",
    "\n",
    "## Notes\n",
    "- Be sure to demonstrate your understanding of the task and the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pprintpp\n",
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "#Comment the below 4 lines if you are loading the data from your local drive\n",
    "# url = 'https://raw.githubusercontent.com/marhcouto/fraud-detection/master/data/card_transdata.csv?raw=true'\n",
    "# #Use this code to overcome SSL verification error when accessing the above https URL\n",
    "# s = requests.get(url).content\n",
    "# data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "#Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    #Mount the google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data = pd.read_csv('/content/drive/MyDrive/card_transdata.csv') #Read the data from the csv file    \n",
    "else:\n",
    "    data = pd.read_csv('card_transdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to control wrapping\n",
    "pd.set_option('display.max_columns', None)  # Do not truncate the list of columns\n",
    "pd.set_option('display.max_rows', None)     # Do not truncate the list of rows\n",
    "pd.set_option('display.width', 1000)        # Set the display width to a large value\n",
    "pd.set_option('display.max_colwidth', 50)   # Set the maximum column width\n",
    "pd.set_option('display.colheader_justify', 'left')  # Justify column headers to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of data\n",
      "(1000000, 8)\n",
      "\n",
      "--- First 5 rows of data ---\n",
      "   distance_from_home  distance_from_last_transaction  ratio_to_median_purchase_price  repeat_retailer  used_chip  used_pin_number  online_order  fraud\n",
      "0  57.877857           0.311140                        1.945940                        1.0              1.0        0.0              0.0           0.0  \n",
      "1  10.829943           0.175592                        1.294219                        1.0              0.0        0.0              0.0           0.0  \n",
      "2   5.091079           0.805153                        0.427715                        1.0              0.0        0.0              1.0           0.0  \n",
      "3   2.247564           5.600044                        0.362663                        1.0              1.0        0.0              1.0           0.0  \n",
      "4  44.190936           0.566486                        2.222767                        1.0              1.0        0.0              1.0           0.0  \n",
      "\n",
      "--- Last 5 rows of data ---\n",
      "        distance_from_home  distance_from_last_transaction  ratio_to_median_purchase_price  repeat_retailer  used_chip  used_pin_number  online_order  fraud\n",
      "999995   2.207101           0.112651                        1.626798                        1.0              1.0        0.0              0.0           0.0  \n",
      "999996  19.872726           2.683904                        2.778303                        1.0              1.0        0.0              0.0           0.0  \n",
      "999997   2.914857           1.472687                        0.218075                        1.0              1.0        0.0              1.0           0.0  \n",
      "999998   4.258729           0.242023                        0.475822                        1.0              0.0        0.0              1.0           0.0  \n",
      "999999  58.108125           0.318110                        0.386920                        1.0              1.0        0.0              1.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "#Examine dataset\n",
    "\n",
    "print(\"\\nShape of data\")\n",
    "print(data.shape)\n",
    "\n",
    "print(\"\\n--- First 5 rows of data ---\")\n",
    "print(data.head(5))\n",
    "\n",
    "print(\"\\n--- Last 5 rows of data ---\")\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Information about the data ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print info\n",
    "print(\"\\n--- Information about the data ---\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observation:</B> The dataset has the following columns:\n",
    "\n",
    "- <b>distance_from_home:</b> Distance of the retailer where transaction was made, from home of the customer, in miles.\n",
    "- <b>distance_from_last_transaction:</b> Distance of current transaction from the prior transaction, in miles.\n",
    "- <b>ratio_to_median_purchase_price:</b> This variable shows how that purchase price in the transaction compares to the average price in the dataset. A value of 1 indicates that the purchase price is same as the average price, a value > 1 indicates that the item purchased is more expensive than the median, while a value < 1 indicates it's cheaper.\n",
    "- <b>repeat_retailer:</b> This is an indicator variable that indicates if there were multiple transactions made with specific retailers 0 = No, 1 = Yes. Note that the actual details of the retailer are not provided.\n",
    "- <b>used_chip:</b> Indicator variable to show if the customer used a card with a chip or not (0 = No, 1 = Yes)\n",
    "- <b>used_pin_number:</b> This is an indicator variable to show if the customer used a pin or not (0 = No, 1 = Yes)\n",
    "- <b>online_order:</b> This is an indicator variable to show if this was an online order or not (0 = No, 1 = Yes)\n",
    "- <b>fraud:</b> The target variable indicating if the given transaction was fraudulent or not. (0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary Statistics ---\n",
      "                                count      mean   std    min  25%   50%   75%    max     \n",
      "distance_from_home              1000000.0  26.63  65.39  0.0  3.88  9.97  25.74  10632.72\n",
      "distance_from_last_transaction  1000000.0   5.04  25.84  0.0  0.30  1.00   3.36  11851.10\n",
      "ratio_to_median_purchase_price  1000000.0   1.82   2.80  0.0  0.48  1.00   2.10    267.80\n",
      "repeat_retailer                 1000000.0   0.88   0.32  0.0  1.00  1.00   1.00      1.00\n",
      "used_chip                       1000000.0   0.35   0.48  0.0  0.00  0.00   1.00      1.00\n",
      "used_pin_number                 1000000.0   0.10   0.30  0.0  0.00  0.00   0.00      1.00\n",
      "online_order                    1000000.0   0.65   0.48  0.0  0.00  1.00   1.00      1.00\n",
      "fraud                           1000000.0   0.09   0.28  0.0  0.00  0.00   0.00      1.00\n"
     ]
    }
   ],
   "source": [
    "# Print summary stats\n",
    "print(\"\\n--- Summary Statistics ---\")\n",
    "print(np.round(data.describe().T,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observations from Summary Statistics:</B>\n",
    "\n",
    "- The columns distance_from_home and distance_from_last_transaction are skewed since their mean and median values are not the same.\n",
    "- The columns distance_from_home, distance_from_last_transaction and ratio_to_median_purchase_price appears to have outliers since their max values are much higher than the mean values. This is also confirmed by the box plots below.\n",
    "- The column repeat_retailer has more 1 values than 0 since it's mean value is > 0.5.\n",
    "- The column used_chip has more 0 values than 1 since it's mean value is < 0.5.\n",
    "- The column used_pin_number has more 0 values than 1 since it's mean value is < 0.5.\n",
    "- The column online_order has more 1 values than 0 since it's mean value is > 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Event Rate ---\n",
      "Event Rate: 8.74%\n"
     ]
    }
   ],
   "source": [
    "# Event rate\n",
    "print(\"\\n--- Event Rate ---\")\n",
    "event_rate = data['fraud'].mean() * 100\n",
    "print(f'Event Rate: {event_rate:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observations:</B> \n",
    "- Fraud detection datasets are often highly imbalanced, with a small percentage of transactions being fraudulent. The event rate helps quantify this imbalance, which is essential for selecting appropriate modeling techniques and evaluation metrics.\n",
    "- An event rate of 8.74% indicates that the dataset is imbalanced, with a relatively small proportion of transactions being fraudulent. This is common in fraud detection datasets, where the majority of transactions are legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Check for missing values and duplicate rows</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check for duplicates ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicates\n",
    "print(\"\\n--- Check for duplicates ---\")\n",
    "dups = data.duplicated()\n",
    "print(dups.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observation:</B> There are no duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values ---\n",
      "distance_from_home                0\n",
      "distance_from_last_transaction    0\n",
      "ratio_to_median_purchase_price    0\n",
      "repeat_retailer                   0\n",
      "used_chip                         0\n",
      "used_pin_number                   0\n",
      "online_order                      0\n",
      "fraud                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observation:</B> There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Boxplots for detecting outliers---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw horizontal boxplots for the continuous variables and look for outliers\n",
    "#rotate the display of the x-axis labels for easy reading\n",
    "print(\"\\n--- Boxplots for detecting outliers---\")\n",
    "#do not show box plots for the 'boolean' variables : 'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order' and 'fraud'\n",
    "box_plot_data = data.drop(['repeat_retailer', 'used_chip', 'used_pin_number', 'online_order', 'fraud'], axis=1)\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=box_plot_data, orient='h')\n",
    "#increase the font size of x-axis and y-axis labels for easy reading\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Counts of Outliers for each Column ---\n",
      "distance_from_home                103631\n",
      "distance_from_last_transaction    124367\n",
      "ratio_to_median_purchase_price     84386\n",
      "repeat_retailer                   118464\n",
      "used_chip                              0\n",
      "used_pin_number                   100608\n",
      "online_order                           0\n",
      "fraud                              87403\n",
      "dtype: int64\n",
      "\n",
      "--- Rows with Outliers ---\n"
     ]
    }
   ],
   "source": [
    "#List the outliers in the dataset\n",
    "print(\"\\n--- Counts of Outliers for each Column ---\")\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).sum()\n",
    "print(outliers)\n",
    "\n",
    "#Print the rows with outliers in the dataset\n",
    "print(\"\\n--- Rows with Outliers ---\")\n",
    "print(data[((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)])\n",
    "\n",
    "#Print the count of rows with outliers\n",
    "print(\"\\n--- Count of Rows with Outliers ---\")\n",
    "print(data[((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the count of rows with outliers that are fraud and non-fraud\n",
    "print(\"\\n--- Count of Rows with Outliers that are Fraud and Non-Fraud ---\")\n",
    "print(data[((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]['fraud'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observations</B>\n",
    "- Nearly half the dataset has outliers.\n",
    "- Also, a large number of rows (~360K) contain outliers and yet represent non-fraudulent data.\n",
    "- Hence we will not treat the outliers and let them remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a line plot of the numeric columns\n",
    "print(\"\\n--- Line plots for numeric columns ---\")\n",
    "plt.figure(figsize=(20,10))\n",
    "#exclude the indicator columns from the line plot, as they are binary\n",
    "#exclude the fraud column as it is the target variable\n",
    "numeric_columns_all = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_columns = numeric_columns_all.drop(['fraud', 'used_chip', 'used_pin_number', 'online_order', 'repeat_retailer'])\n",
    "#create separate line plots for each column\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.plot(data[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Data Imbalance</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for data imbalance\n",
    "print(\"\\n--- Data Imbalance ---\")\n",
    "print(data['fraud'].value_counts())\n",
    "\n",
    "#Plot the data imbalance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Plot histogram of the target variable to show the imbalance in the dataset\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "ax = sns.histplot(data['fraud'], kde=True, color=\"red\")\n",
    "plt.title('Histogram of Fraud')\n",
    "# Annotate the counts on top of the bars\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observation:</B> The dataset is imbalanced as the target variable 'fraud' has a low number of rows (87403) for the class i.e fraud = Yes (1), and a very large number of rows (912597) for the class i.e. fraud = No (0). \n",
    "This is somewhat expected since, in a normal situation, the vast majority of financial transactions should be valid and only a minority should be fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Bivariate Analysis<H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we analyze pairs of variables to look for correlations between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Correlation Heatmap</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for correlation between the variables\n",
    "print(\"\\n--- Correlation between Variables ---\")\n",
    "correlation = data.corr()\n",
    "print(correlation)\n",
    "\n",
    "#increase the font size of the labels in the heatmap\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "#Plot the correlation matrix\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Bar chart showing correlation of columns w.r.t target variable</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar chart of the correlation values of the variables with the target variable\n",
    "print(\"\\n--- Correlation with Target Variable ---\")\n",
    "\n",
    "#set the font size chart\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "#set the font size for the x and y axis labels\n",
    "plt.rcParams.update({'xtick.labelsize': 10, 'ytick.labelsize': 10})\n",
    "\n",
    "#change the color of the bars to light blue\n",
    "#rotate the chart horizontally for easy reading\n",
    "correlation['fraud'].sort_values(ascending=False).plot(kind='barh', color='lightblue')\n",
    "\n",
    "#draw a vertical line at 0\n",
    "plt.axvline(x=0, color='red', linewidth=0.5)\n",
    "#show the values at the end of the bars\n",
    "#add a gap between the end of the bar and the value\n",
    "for index, value in enumerate(correlation['fraud'].sort_values(ascending=False)):\n",
    "    plt.text(value, index, str(round(value,2)), va='center')\n",
    "#increase font size of title\n",
    "plt.title('Correlation with Target Variable', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Correlation Observations:</B> \n",
    "- The 'ratio_to_median_purchase_price' feature variable shows a moderate positive correlation with the target variable 'fraud'. This implies that the purchase of higher value products is more often fraudulent than lower value products.\n",
    "- The variables 'online_order' and 'distance_from_home' also show a positive correlation with fraud, indicating that fraudulent transactions may typically occur online or when the customer is away from home.\n",
    "- The used_pin variable is negatively correlated with fraud, indicating that use of a pin could secure transactions against fraud.\n",
    "- The repeat_retailer does not have any correlation with the target variable. This implies that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Pair Plots</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Takes 1-2 minutes to run\n",
    "#Create a pairplot of the numeric columns\n",
    "print(\"\\n--- Pairplot of Numeric Columns ---\")\n",
    "#reduce the font size of the labels for better readability\n",
    "sns.set(font_scale=0.5)\n",
    "sns.pairplot(data[numeric_columns], diag_kind='kde')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Scaling of numeric variables</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a line plot of the numeric columns\n",
    "print(\"\\n--- Line plots for numeric columns after min-max and standard scaling ---\")\n",
    "plt.figure(figsize=(20,10))\n",
    "#exclude the indicator columns from the line plot, as they are binary\n",
    "#exclude the fraud column as it is the target variable\n",
    "numeric_columns_all = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_columns = numeric_columns_all.drop(['fraud', 'used_chip', 'used_pin_number', 'online_order', 'repeat_retailer'])\n",
    "#create separate line plots for each column\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    #increase the font size of the title for better readability\n",
    "    plt.rc('axes', titlesize=10)\n",
    "    \n",
    "    #increase the x and y axis font size for better readability\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "    plt.rc('ytick', labelsize=10)\n",
    "\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.plot(data[col])\n",
    "    plt.title(col, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Observation:</B> Due to standard scaling, all feature columns now have means close to 0 and standard deviations close to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Prepare Dataset for Training:</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the atrributes (X) and the label (y)\n",
    "X = data.drop('fraud', axis=1)\n",
    "y = data['fraud']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Use stratification to ensure that the event rate is maintained in the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"\\n Shape of features in the training data\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\n Shape of features in the test data\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Model construction and training</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Decision Tree Classifier Model</H4>\n",
    "In this section, we will build and train a Decision Tree Classifier model. This model will just be used for comparision with the target model which is based on Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Decision Tree Model Construction and Training ---\")\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "# max_depth is maximum number of levels in the tree\n",
    "# random_state is the seed value for the random number generator, to ensure reproducibility\n",
    "model_dt = DecisionTreeClassifier(max_depth=3, random_state=42) \n",
    "\n",
    "# Train the model on the training data\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> Decision Tree Model Valuation:</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Decision Tree Model Performance Metrics ---\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "confusion_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "classification_rep_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n--- Decision Tree Confusion Matrix: ---\")\n",
    "print(confusion_dt)\n",
    "print(\"\\n--- Decision Tree Classification Report: ---\")\n",
    "print(classification_rep_dt)\n",
    "\n",
    "print(\"\\n--- Tree Diagram Of The Decision Tree Model ---\")\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(25, 10))\n",
    "plot_tree(model_dt, \n",
    "          filled=True, \n",
    "          feature_names=['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price',\n",
    "                         'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order'],\n",
    "          class_names=['Non-Fraud', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Performance Evaluation for Decision Tree Model:</B>\n",
    "\n",
    "-Overall, the Decision Tree Model is performing well, with F1-score of 0.99 for class 0 (non-fraud) and 0.89 for class 1 (fraud)\n",
    "-Due to data imbalance, the precision (0.99) and recall (0.99) for class 0 (non-fraud) is higher than the precision (0.87) and recall (0.91) for class 1 (fraud) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> Random Forest Classifier Model </H4>\n",
    "In this section, we build and train a baseline Random Forest classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to plot the confusion matrix\n",
    "def plot_confusion_matrix(confusion_rf):\n",
    "    print(\"\\n--- Confusion Matrix: ---\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_rf) \n",
    "\n",
    "    #Change the x-axis and y-axis labels: 0 - No Default, 1 - Default\n",
    "    disp = disp.plot(cmap='YlGn')\n",
    "    disp.ax_.set_xticklabels(['No Fraud', 'Fraud'], fontsize=8)\n",
    "    disp.ax_.set_yticklabels(['No Fraud', 'Fraud'], fontsize=8)\n",
    "\n",
    "    #Show the text True Positive, False Negative, False Positive, True Negative in the confusion matrix\n",
    "    disp.ax_.text(0, 0, f\"True Negatives\\n\\n\", ha=\"center\", va=\"center\", color=\"white\", fontsize=8)\n",
    "    disp.ax_.text(0, 1, f\"False Negatives\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "    disp.ax_.text(1, 0, f\"False Positives\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "    disp.ax_.text(1, 1, f\"True Positives\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "    # #Change the font size of the values but do not redisplay the text in the confusion matrix\n",
    "    # disp.ax_.text(0, 0, f\"{confusion_rf[0,0]}\\n\\n\", ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "    # disp.ax_.text(0, 1, f\"{confusion_rf[1,0]}\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    # disp.ax_.text(1, 0, f\"{confusion_rf[0,1]}\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    # disp.ax_.text(1, 1, f\"{confusion_rf[1,1]}\\n\\n\", ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "    #set the font size of the x and y axis labels\n",
    "    disp.ax_.xaxis.label.set_size(8)\n",
    "    disp.ax_.yaxis.label.set_size(8)\n",
    "\n",
    "    #set the font size of the scale bar on the right side\n",
    "    disp.ax_.images[-1].colorbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "    #draw border around the confusion matrix\n",
    "    disp.ax_.spines['top'].set_color('black')\n",
    "    disp.ax_.spines['bottom'].set_color('black')\n",
    "    disp.ax_.spines['left'].set_color('black')\n",
    "    disp.ax_.spines['right'].set_color('black')\n",
    "\n",
    "    #draw a horizontal line to separate the actual and predicted labels\n",
    "    disp.ax_.axhline(y=0.5, color='black', linewidth=1)\n",
    "    disp.ax_.axvline(x=0.5, color='black', linewidth=1)\n",
    "\n",
    "    #remove the white color grid lines\n",
    "    disp.ax_.grid(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay \n",
    "\n",
    "print(\"\\n--- Random Forest Model Performance Metrics ---\")\n",
    "\n",
    "#Initialize a decision tree classifier with default parameters\n",
    "#max_depth is maximum number of levels in the tree\n",
    "#set random_state to a fixed number for reproducibility\n",
    "model_rf = RandomForestClassifier(max_depth=3, random_state=42) \n",
    "\n",
    "# Train the model on the training data\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "confusion_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n--- Random Forest Confusion Matrix: ---\")\n",
    "print(confusion_rf)\n",
    "print(\"\\n--- Random Forest Classification Report: ---\")\n",
    "print(classification_rep_rf)\n",
    "\n",
    "plot_confusion_matrix(confusion_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Random Forest Confusion Matrix Observations:</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"\\n--- ROC-AUC Plot To Detect Overfitting in Random Forest Model ---\")\n",
    "# Get the predicted probabilities for the positive class on the training set\n",
    "y_train_pred_rf = model_rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Compute the ROC curve for the training set\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_rf)\n",
    "\n",
    "# Compute the AUC score for the training set\n",
    "auc_train = roc_auc_score(y_train, y_train_pred_rf)\n",
    "\n",
    "# Get the predicted probabilities for the positive class on the test set\n",
    "y_test_pred_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute the ROC curve for the test set\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_rf)\n",
    "\n",
    "# Compute the AUC score for the test set\n",
    "auc_test = roc_auc_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_train, tpr_train, label=f'Training AUC = {auc_train:.2f}', color='blue')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test AUC = {auc_test:.2f}', color='green')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red')\n",
    "#Set the x and y axis labels\n",
    "plt.xlabel('False Positive Rate', fontsize=10)\n",
    "plt.ylabel('True Positive Rate', fontsize=10)\n",
    "plt.title('ROC Curve')\n",
    "\n",
    "plt.rc('axes', titlesize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "#Display the legend\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Comparative Analysis of Models</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08213d",
   "metadata": {},
   "source": [
    "A comparative analysis of the Random Forest and Decision Tree models is provided below and consists of:\n",
    "- <B>ROC Curve Analysis:</B> Here we compare the two binary classification models using the ROC (Receiver Operating Characteristic) curve.It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. The area under the ROC curve (AUC) is a single scalar value that summarizes the overall performance of the model. A higher AUC value indicates a better model i.e. it can distinguish between the classes more effectively.\n",
    "- <B>Model Metrics Comparison:</B>- A DataFrame is created to capture and display the performance metrics of each model in a tabular format. This provides a clear, concise way to compare the models' performance side-by-side. Bar charts are used to visually compare these metrics across different models. This visual representation aids in quickly discerning which models perform better in terms of accuracy, recall, and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f2244",
   "metadata": {},
   "source": [
    "<H4>ROC Curve Analysis</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ROC curve for the Random Forest and Decision Tree models and calculate the AUC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Calculate the probabilities for the Random Forest and Decision Tree models\n",
    "y_pred_prob_rf = model_rf.predict_proba(X_test)[:,1]\n",
    "y_pred_prob_dt = model_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "#Calculate the FPR, TPR and thresholds for the Random Forest and Decision Tree models\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_prob_rf)\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, y_pred_prob_dt)\n",
    "\n",
    "#Calculate the AUC for the Random Forest and Decision Tree models\n",
    "auc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "auc_dt = roc_auc_score(y_test, y_pred_prob_dt)\n",
    "\n",
    "#Plot the ROC curve for the Random Forest and Decision Tree models\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#Plot the ROC curve for the Random Forest model\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})', color='red')\n",
    "\n",
    "#Plot the ROC curve for the Decision Tree model\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.2f})', color='blue')\n",
    "\n",
    "#Plot the 45 degree line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "#increase the font size of the labels\n",
    "plt.rc('axes', titlesize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "#Set the x and y axis labels\n",
    "plt.xlabel('False Positive Rate', fontsize=10)\n",
    "plt.ylabel('True Positive Rate', fontsize=10)\n",
    "\n",
    "#Set the title of the plot\n",
    "plt.title('ROC Curve')\n",
    "\n",
    "#Display the legend\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout\n",
    "#Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>ROC Curve Comparison Observations:</B>\n",
    "- Both Random Forest and Decision Trees  have AUC = 1. This indicates that both models are able to perfectly distinguish between the positive and negative classes without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Model Metrics Comparison</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming accuracy_dt, accuracy_rf, precision_dt, precision_rf, recall_dt, recall_rf, f1_dt, and f1_rf are already defined\n",
    "\n",
    "# Collect the performance metrics in a DataFrame\n",
    "# Obtain the performance metrics for the Decision Tree and Random Forest models for both\n",
    "# Classes: Non-Fraud and Fraud\n",
    "precision_dt_non_fraud = precision_score(y_test, y_pred_dt, pos_label=0)\n",
    "recall_dt_non_fraud = recall_score(y_test, y_pred_dt, pos_label=0)\n",
    "f1_dt_non_fraud = f1_score(y_test, y_pred_dt, pos_label=0)\n",
    "\n",
    "precision_dt_fraud = precision_score(y_test, y_pred_dt, pos_label=1)\n",
    "recall_dt_fraud = recall_score(y_test, y_pred_dt, pos_label=1)\n",
    "f1_dt_fraud = f1_score(y_test, y_pred_dt, pos_label=1)\n",
    "\n",
    "precision_rf_non_fraud = precision_score(y_test, y_pred_rf, pos_label=0)\n",
    "recall_rf_non_fraud = recall_score(y_test, y_pred_rf, pos_label=0)\n",
    "f1_rf_non_fraud = f1_score(y_test, y_pred_rf, pos_label=0)\n",
    "\n",
    "precision_rf_fraud = precision_score(y_test, y_pred_rf, pos_label=1)\n",
    "recall_rf_fraud = recall_score(y_test, y_pred_rf, pos_label=1)\n",
    "f1_rf_fraud = f1_score(y_test, y_pred_rf, pos_label=1)\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest', 'Decision Tree', 'Random Forest', 'Decision Tree', 'Random Forest', 'Decision Tree', 'Random Forest'],\n",
    "    'Metric': ['Accuracy', 'Accuracy', 'Precision', 'Precision', 'Recall', 'Recall', 'F1 Score', 'F1 Score'],\n",
    "    'Non-Fraud': [accuracy_dt, accuracy_rf, precision_dt_non_fraud, precision_rf_non_fraud, recall_dt_non_fraud, recall_rf_non_fraud, f1_dt_non_fraud, f1_rf_non_fraud],\n",
    "    'Fraud': [accuracy_dt, accuracy_rf, precision_dt_fraud, precision_rf_fraud, recall_dt_fraud, recall_rf_fraud, f1_dt_fraud, f1_rf_fraud]\n",
    "})\n",
    "\n",
    "#combine Model and Metric columns to create a new column\n",
    "metrics['Model_Metric'] = metrics['Model'] + ' ' + metrics['Metric']\n",
    "\n",
    "# Print the performance metrics dataframe\n",
    "print(\"\\n--- Performance Metrics for Decision Tree and Random Forest Models ---\")\n",
    "print(np.round(metrics,2))\n",
    "\n",
    "# Plot the horizontal bar chart\n",
    "# Use a different color for each metric\n",
    "metrics.set_index('Model_Metric').plot(kind='barh', figsize=(10, 4))\n",
    "plt.title('Comparison of Decision Tree and Random Forest Models')\n",
    "plt.xlabel('Score', fontsize=10)\n",
    "plt.ylabel('Model_Metric', fontsize=10)\n",
    "#Increase font size for x and y axis labels\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "plt.xlim(0, 1)\n",
    "#increas the font size of the legend\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104978a",
   "metadata": {},
   "source": [
    "<B>Comparison of Metrics of Decision Tree and Random Forest Models :</B>\n",
    "\n",
    "| Class      | Metric         | Decision Tree | Random Forest  | Comments       |\n",
    "|------------|----------------|---------------|----------------|----------------|\n",
    "| N/A | Accuracy   | 0.98         | 0.97           | DT model has slightly higher accuracy, but due to imbalanced data, this metric is not significant. |\n",
    "| 0 (Non-Fraud) | Precision  | 0.99           | 0.97           | RF model has slightly lower precision for class 0. This implies that the DT model is more accurate in its predictions of the non-fraudulent class and is less likely to incorrectly classify legitimate transactions as fraudulent. |\n",
    "| 0 (Non-Fraud) | Recall     | 0.99           | 1.00           | RF model has slightly higher recall for class 0. This implies that the RF model is slightly more effective at identifying all the relevant instances of the non-fraudulent class.  |\n",
    "| 0 (Non-Fraud) | F1 Score   | 0.99           | 0.99          | RF has same F1 score for class 0, as DT. |\n",
    "| 1 (Fraud)     | Precision  | 0.87           | 1.00           | RF model has higher precision for class 1. This implies that the RF model is more accurate in its predictions for the fraudulent class and is more likely to correctly classify illegitimate transactions as fraudulent. | |\n",
    "| 1 (Fraud)     | Recall     | 0.91           | 0.70           | DT model has significantly higher recall for class 1.This implies that the DT model is much more effective at identifying all the relevant instances of the fraudulent class.  | |\n",
    "| 1 (Fraud)     | F1 Score   | 0.89           | 0.82           | Decision Tree has a higher F1 score for class 1. This is due to higher recall and precision scores for class 1.|\n",
    "\n",
    "Overall, while both models perform well, the Decision Tree model is better at identifying fraudulent transactions (higher recall), whereas the Random Forest model is better at correctly identifying non-fraudulent transactions (higher precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fe255",
   "metadata": {},
   "source": [
    "<H4>Functional Comparison of Decision Tree and RandomForest Models:</H4>\n",
    "\n",
    "<B>Decision Tree Model:</B>\n",
    "\n",
    "|Pros | Cons|\n",
    "|------|------|\n",
    "|Simplicity and Interpretability: Decision trees are easy to understand and interpret. The tree structure allows for clear visualization of the decision-making process.|Overfitting: Decision trees are prone to overfitting, especially when the tree is deep and complex. This can lead to poor generalization to new data.|\n",
    "|Non-Parametric: Decision trees do not assume any underlying distribution of the data, making them flexible and applicable to a wide range of problems. |Instability: Small changes in the data can result in significantly different tree structures, making decision trees sensitive to variations in the training data.|\n",
    "|Handling of Non-Linear Relationships: Decision trees can capture non-linear relationships between features and the target variable. |Bias-Variance Tradeoff: Decision trees can have high variance and low bias, leading to overfitting. Pruning techniques can help mitigate this issue but may not always be sufficient.|\n",
    "|Feature Importance: Decision trees provide a measure of feature importance, helping to identify the most influential features in the dataset. |\n",
    "|Minimal Data Preparation: Decision trees require little data preprocessing, such as normalization or scaling.|\n",
    "\n",
    "\n",
    "<B>Random Forest Model:</B>\n",
    "\n",
    "|Pros|Cons|\n",
    "|------|------|\n",
    "|Reduced Overfitting: Random forests combine multiple decision trees to reduce overfitting. By averaging the predictions of many trees, they improve generalization to new data.|Complexity: Random forests are more complex and computationally intensive compared to individual decision trees. |Training and prediction times can be longer, especially with a large number of trees.|\n",
    "Robustness: Random forests are more robust to variations in the training data compared to individual decision trees. They are less sensitive to outliers and noise.| Interpretability: While individual decision trees are easy to interpret, random forests are more challenging to interpret due to the ensemble of multiple trees.\n",
    "|Improved Accuracy: Random forests generally provide higher accuracy and better performance compared to individual decision trees.|Memory Usage: Random forests require more memory to store multiple trees, which can be a limitation for large datasets|\n",
    "|Feature Importance: Like decision trees, random forests provide a measure of feature importance, helping to identify the most influential features.|\n",
    "|Handling of Missing Values: Random forests can handle missing values by using surrogate splits or by averaging predictions from trees that do not use the missing feature.|\n",
    "\n",
    "<B>Summary:</B>\n",
    "- Decision Trees are simple, interpretable, and easy to visualize, but prone to overfitting and instability.\n",
    "- Random Forest Models are more robust, accurate, and less prone to overfitting, but more complex, computationally intensive, and harder to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d890744",
   "metadata": {},
   "source": [
    "# Extra Credit: Advanced Model Enhancement and Evaluation\n",
    "\n",
    "## Objective\n",
    "Advance your data science expertise by applying more sophisticated techniques in model enhancement and evaluation within the context of fraud detection. This extra credit section includes data balancing, implementing cross-validation, and conducting a feature importance analysis.\n",
    "\n",
    "## Tasks\n",
    "1. **Balancing the Data**:\n",
    "   - Utilize a technique like SMOTE or undersampling to balance the dataset.\n",
    "   - Rebuild the Random Forest model using the balanced dataset.\n",
    "2. **Cross-Validation**:\n",
    "   - Implement 5-fold cross-validation for the Random Forest model.\n",
    "   - Analyze the model's performance and stability based on cross-validation results.\n",
    "3. **Feature Importance Analysis**:\n",
    "   - Determine feature importance using the Random Forest model.\n",
    "   - Present the feature importances in a table and a graph.\n",
    "\n",
    "## Extra Credit Grading Rubric\n",
    "\n",
    "**Total Points: 50**\n",
    "\n",
    "1. **Balancing the Data (15 Points)**:\n",
    "   - Correct application of a technique to balance the dataset: 7 points\n",
    "   - Successful rebuilding of the Random Forest model with balanced data: 8 points\n",
    "\n",
    "2. **Cross-Validation (20 Points)**:\n",
    "   - Proper implementation of 5-fold cross-validation: 10 points\n",
    "   - Comprehensive analysis of cross-validation results: 10 points\n",
    "\n",
    "3. **Feature Importance Analysis (15 Points)**:\n",
    "   - Accurate determination of feature importances: 7 points\n",
    "   - Clear and informative presentation of feature importances in a table and graph: 8 points\n",
    "\n",
    "## Submission Guidelines for Extra Credit\n",
    "- Include your extra credit work in the same Jupyter Notebook or Python script as the main assignment.\n",
    "- Clearly label the sections and outputs for the extra credit tasks.\n",
    "- Ensure your analysis and visualizations are comprehensible and well-explained.\n",
    "\n",
    "## Notes\n",
    "- This extra credit section is optional and designed for students interested in deeper exploration of data science techniques.\n",
    "- Focus on the quality of analysis and clarity of presentation for awarding points in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Balancing The Data</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Exploratory Data Analysis, we have noted that the data is imbalanced i.e. there are more representatives of Class 0 (non-fraud) than of Class 1 (fraud). If the imbalance is very high (>10), it can be addressed by using SMOTE algorithm to synthesize additional data for class 0 by sampling existing data. To avoid data leakage/contamination, SMOTE needs to be applied only to training data after splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print imbalance ratio\n",
    "print(\"Majority class count:\", y_train.value_counts()[0])\n",
    "print(\"Minority class count:\", y_train.value_counts()[1])\n",
    "print(\"Imbalance ratio before SMOTE oversampling:\", np.round(y_train.value_counts()[0] / y_train.value_counts()[1],2))\n",
    " \n",
    "# use SMOTE to oversample the minority class in the traiing set if the \n",
    "# imbalance ratio is greater than 10\n",
    "from imblearn.over_sampling import SMOTE\n",
    "if y_train.value_counts()[0] / y_train.value_counts()[1] > 10:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Imbalance ratio after SMOTE oversampling:\", np.round(y_train.value_counts()[0] / y_train.value_counts()[1],2))\n",
    "    #plot histogram of the target variable after smote oversampling to confirm that\n",
    "    #the classes are balanced\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.histplot(y_train, kde=True, color=\"blue\")\n",
    "else:\n",
    "    print(\"No need for SMOTE oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Cross-validation</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical technique used to evaluate the performance and generalizability of a machine learning model. It involves partitioning the dataset into multiple subsets, training the model on some subsets (training set), and evaluating it on the remaining subsets (validation set). This process is repeated multiple times, and the results are averaged to provide a more reliable estimate of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross-Validation: The dataset is divided into k equal-sized folds. The model is trained on k-1 folds and validated on the remaining fold. This process is repeated k times, with each fold used as the validation set once. The results are averaged to obtain the final performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This block takes 3-4 minutes to run without n_jobs=-1 parameter setting\n",
    "print(\"\\n--- Random Forest Model Performance Metrics After Balancing Data and 5-fold Cross Validation---\")\n",
    "#Create a K-fold cross-validation object and use it for training the model, with K = 5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "#print value counts of the target variable in the training set\n",
    "print(\"Value counts of the target variable in the training set\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "#Create a KFold object with 5 splits\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Initialize a new instance of Random Forest classifier to use in cross-validation\n",
    "#set random_state to a fixed number for reproducibility\n",
    "model_rf2 = RandomForestClassifier(max_depth=3, random_state=42,n_jobs=-1)\n",
    "\n",
    "#Train the model using cross-validation\n",
    "cv_scores = cross_val_score(model_rf2, X_train, y_train, cv=kf)\n",
    "\n",
    "#Print the cross-validation scores\n",
    "print(\"\\n--- Cross-Validation Scores ---\")\n",
    "print(cv_scores)\n",
    "\n",
    "#Print the mean and standard deviation of the cross-validation scores\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.2f}\")\n",
    "print(f\"CV Score Standard Deviation: {cv_scores.std():.2f}\")\n",
    "\n",
    "#Train the Random Forest model on the training data\n",
    "model_rf2.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_rf2 = model_rf2.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_rf2 = accuracy_score(y_test, y_pred_rf2)\n",
    "confusion_rf2 = confusion_matrix(y_test, y_pred_rf2)\n",
    "classification_rep_rf2 = classification_report(y_test, y_pred_rf2)\n",
    "\n",
    "#Print the results\n",
    "print(f\"Accuracy: {accuracy_rf2:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_rf2)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_rf2)\n",
    "\n",
    "#Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d3555",
   "metadata": {},
   "source": [
    "<B>Observations after retraining model with balanced target variable:</B>\n",
    "\n",
    "The precision, recall and f1-score have improved for class 1 (fraud) as compared a model trained on an unbalanced target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Feature Importance Analysis</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb73968",
   "metadata": {},
   "source": [
    "<B>Feature Importance from Cross-Validated Model:</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_rf2.feature_importances_\n",
    "# Original feature names\n",
    "feature_names = data.columns[:-1]\n",
    "\n",
    "# Verify the length of feature names matches the length of feature importances\n",
    "assert len(feature_names) == len(feature_importance), \"Feature name and importance length mismatch\"\n",
    "\n",
    "# Create the Feature Importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the Feature Importance DataFrame\n",
    "print(\"\\n--- Feature Importance Table ---\")\n",
    "print(importance_df)\n",
    "\n",
    "print(\"\\n--- Feature Importance Bar Chart ---\")\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature')\n",
    "#print the values at the end of the bars. Leave a gap between the end of the bar and the value\n",
    "for i, v in enumerate(importance_df['Importance'].head(10)):\n",
    "    plt.text(v, i, round(v,2), ha='left', va='center', fontsize=10)\n",
    "\n",
    "#increase the font size of the x and y axis labels\n",
    "plt.rc('axes', titlesize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "plt.xlabel('Feature Importance', fontsize=10)\n",
    "plt.ylabel('Feature', fontsize=10)\n",
    "\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97c6f3",
   "metadata": {},
   "source": [
    "<B>Feature Importance using Gini Coefficient:</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Feature Importance Gini Coefficient Bar Chart ---\")\n",
    "\n",
    "importance_dt = model_dt.feature_importances_\n",
    "\n",
    "# Sort the feature importance in ascending order\n",
    "indices_dt = np.argsort(importance_dt)\n",
    "\n",
    "# Create a Gini coefficient plot for the Decision Tree model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(importance_dt)), importance_dt[indices_dt], align='center')\n",
    "plt.yticks(range(len(importance_dt)), X_train.columns[indices_dt], rotation=0)\n",
    "plt.title('Gini Coefficient Plot for Decision Tree Model')\n",
    "# Increase font size of the x and y axis labels\n",
    "plt.xlabel('Gini Coefficient', fontsize=10)\n",
    "plt.ylabel('Features', fontsize=10)\n",
    "\n",
    "# Increase the font size of the labels\n",
    "plt.rc('axes', titlesize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "# Show values at the end of the bars. Leave a gap between the end of the bar and the value\n",
    "for i, v in enumerate(importance_dt[indices_dt]):\n",
    "    plt.text(v, i, round(v, 2), ha='left', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f30aa",
   "metadata": {},
   "source": [
    "<B>Gini Coefficient Observations:</B>\n",
    "The Gini Coefficient chart helps us to determine the best feature to use as the root node for the decision tree. To do this, we will calculate the Gini impurity for each feature and select the feature with the lowest Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210600d5",
   "metadata": {},
   "source": [
    "<B>Feature Importance Observations</B>\n",
    "\n",
    "Both the feature importances chart and the Gini coefficients chart indicate that:\n",
    "- The feature with the highest importance is <B>ratio_to_median_purchase_price</B>. This implies that transactions with higher prices are more likely to be fraudulent.\n",
    "- The feature with the least importance is <B>repeat_retailer</B>. This implies that fraudulent transactions can happen at the same retailer or at different retailers.\n",
    "- The features <B>online_order</B> and <B>distance_from_home</B> are next in importance respectively, implying that fraudulent orders are less likely in transactions made in person or closer to the customer's home.\n",
    "- The feature <B>used_pin</B> is next in importance, implying that transactions involving the entry of a pin, like those using a debit card for instance, are more susceptible to fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed47167",
   "metadata": {},
   "source": [
    "<H4>Re-training the model with reduced features</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This block of code takes 5-6 minutes to run without njobs=-1 parameter setting\n",
    "print(\"\\n--- Random Forest Model Performance Metrics After Reducing Features---\")\n",
    "# Create a K-fold cross-validation object and use it for training the model, with K = 5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#drop the feature repeat_retailer as it has low feature importance\n",
    "X_train.drop('repeat_retailer', axis=1, inplace=True)\n",
    "X_test.drop('repeat_retailer', axis=1, inplace=True)\n",
    "\n",
    "#Create a KFold object with 5 splits\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Initialize a new instance of Random Forest classifier to use in cross-validation\n",
    "#set random_state to a fixed number for reproducibility\n",
    "model_rf2 = RandomForestClassifier(max_depth=3, random_state=42,n_jobs=-1)\n",
    "\n",
    "#Train the model using cross-validation\n",
    "cv_scores = cross_val_score(model_rf2, X_train, y_train, cv=kf)\n",
    "\n",
    "#Print the cross-validation scores\n",
    "print(\"\\n--- Cross-Validation Scores ---\")\n",
    "print(cv_scores)\n",
    "\n",
    "#Print the mean and standard deviation of the cross-validation scores\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.2f}\")\n",
    "print(f\"CV Score Standard Deviation: {cv_scores.std():.2f}\")\n",
    "\n",
    "#Train the Random Forest model on the training data\n",
    "model_rf2.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_rf2 = model_rf2.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_rf2 = accuracy_score(y_test, y_pred_rf2)\n",
    "confusion_rf2 = confusion_matrix(y_test, y_pred_rf2)\n",
    "classification_rep_rf2 = classification_report(y_test, y_pred_rf2)\n",
    "\n",
    "#Print the results\n",
    "print(f\"Accuracy: {accuracy_rf2:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_rf2)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_rf2)\n",
    "\n",
    "#Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8049ad",
   "metadata": {},
   "source": [
    "<B>Observations after retraining model with reduced features:</B>\n",
    "\n",
    "The precision, recall and f1-score have improved for class 1 (fraud) as compared a model trained on all features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459c6c2",
   "metadata": {},
   "source": [
    "<B>Comparison of Metrics of Random Forest Models Before and After Modifications:</B>\n",
    "\n",
    "Note: 'tuning' => Balancing, 5-fold Cross-validation\n",
    "\n",
    "| Class      | Metric         | Baseline RF   |'Tuned' RF with reduced Features    | 'Tuned' RF with all Features   | Comments       |\n",
    "|------------|----------------|---------------|---------------|----------------|----------------|\n",
    "| N/A | Accuracy   | 0.97        | 0.97 |1.00      |    Accuracy seems to better when using a tuned model with all features, but this metric is not considered for imbalanced datasets. |\n",
    "| 0 (Non-Fraud) | Precision | 0.97      | 1.00 | 1.00                      |  Precision for class 0 has improved after tuning. |\n",
    "| 0 (Non-Fraud) | Recall      | 1.00  | 0.97  |1.00                                  | The recall value for class 0 has reduced slightly after removing features.  |\n",
    "| 0 (Non-Fraud) | F1 Score   | 0.99         | 0.98 |1.00                           | The F1 score class 0 has reduced slightly after removing features. |\n",
    "| 1 (Fraud)     | Precision   | 1.00         | 0.74  |0.98                          | The precision for class 1 has reduced after removing features. But the tuned model with all features has comparable precison with baseline model. | |\n",
    "| 1 (Fraud)     | Recall      | 0.70        | 1.00   |0.99                          | The recall of the tuned model has significantly improved for class 1, with and without removing features.  | |\n",
    "| 1 (Fraud)     | F1 Score     | 0.82        | 0.85   |0.99                         | The tuned model has a higher F1 score for class 1 after removing features, but the tuned model with all features has the best F1 score for class 1.|\n",
    "\n",
    "Overall, the 'tuned' RF model, with all features, has the best performance in identifying fraudulent transactions due to higher recall and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6007081",
   "metadata": {},
   "source": [
    "<H3>Reflection and Discussion</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8828f6",
   "metadata": {},
   "source": [
    "We started with a Decision Tree model and proceeded to build a Random Forest (RF) model. \n",
    "\n",
    "The baseline RF model with default parameters performed well on Class 0 (Non-fraud) cases but did not perform that well on Class 1 (Fraud) cases, relative to the baseline DT model. \n",
    "\n",
    "We were able to build and train a high-performance fraud detection model by significantly improving the performance of the baseline RF model using the following techniques:\n",
    "\n",
    "- We used SMOTE (Synthetic Minority Oversampling Technique) algorithm to smoothen out the imbalances in the training dataset. The training dataset originally had an overwhelming majority of rows in favor of Class 0, and SMOTE was used to sample and auto-generate more rows having target label Class 1. The testing dataset was left untouched.\n",
    "- We used k-fold (k = 5) cross-validation during model training. It involves partitioning the dataset into k equal-sized folds, training the model on k-1 folds, and validating it on the remaining fold. This process is repeated k times, with each fold used as the validation set once. The results are averaged to provide a more reliable estimate of the model's performance. This also reduces overfitting.\n",
    "- We carried out feature importance analysis to identify and remove unnecessary features and this reduced the overfitting as well as the training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
